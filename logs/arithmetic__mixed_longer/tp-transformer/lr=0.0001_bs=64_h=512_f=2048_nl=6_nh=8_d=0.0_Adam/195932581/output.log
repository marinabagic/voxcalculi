Arguments:
	seed=195932581
	model_name='tp-transformer'
	module_name='arithmetic__mixed_longer'
	load_model='C:\\Users\\anteg\\Desktop\\PROJEKTI\\TP-Transformer-master\\trained\\lr=0.0001_bs=128_h=512_f=2048_nl=6_nh=8_d=0.0_Adam_\\195932581\\best_eval_model.pt'
	eval_mode=True
	n_steps=10000
	max_strikes=1000
	log_every=50
	eval_every=200
	full_loader=False
	force_remove=False
	force_reload=False
	no_train=False
	log_folder='logs\\arithmetic__mixed_longer\\tp-transformer\\lr=0.0001_bs=64_h=512_f=2048_nl=6_nh=8_d=0.0_Adam\\195932581'
	log_suffix=''
	optimizer='Adam'
	learning_rate=0.0001
	beta1=0.9
	beta2=0.995
	batch_size=64
	max_abs_grad_norm=0.1
	grad_accum_steps=1
	dropout=0.0
	hidden=512
	n_layers=6
	n_heads=8
	filter=2048
	d_r=0
	device=device(type='cuda')
using JIT loader
Loading JIT datasets ...
Creating iterators ...
Loading JIT datasets ...
Creating iterators ...
Building model ...
done. 49178624 trainable parameters.

eval: loss=0.9899 acc=0.1856 b/sec=0.12 time=0.3 min
run:  logs\arithmetic__mixed_longer\tp-transformer\lr=0.0001_bs=64_h=512_f=2048_nl=6_nh=8_d=0.0_Adam\195932581
best: loss=0.1620 acc=0.7796 best since 0 steps and 28122416.4 min

Arguments:
	seed=195932581
	model_name='tp-transformer'
	module_name='arithmetic__mixed_longer'
	load_model='C:\\Users\\anteg\\Desktop\\PROJEKTI\\TP-Transformer-master\\trained\\arithmetic\\lr=0.0001_bs=128_h=512_f=2048_nl=6_nh=8_d=0.0_Adam_\\195932581\\best_eval_model.pt'
	eval_mode=True
	n_steps=10000
	max_strikes=1000
	log_every=50
	eval_every=200
	full_loader=False
	force_remove=False
	force_reload=False
	no_train=False
	log_folder='logs\\arithmetic__mixed_longer\\tp-transformer\\lr=0.0001_bs=64_h=512_f=2048_nl=6_nh=8_d=0.0_Adam\\195932581'
	log_suffix=''
	optimizer='Adam'
	learning_rate=0.0001
	beta1=0.9
	beta2=0.995
	batch_size=64
	max_abs_grad_norm=0.1
	grad_accum_steps=1
	dropout=0.0
	hidden=512
	n_layers=6
	n_heads=8
	filter=2048
	d_r=0
	device=device(type='cuda')
using JIT loader
Loading JIT datasets ...
Creating iterators ...
Loading JIT datasets ...
Creating iterators ...
Building model ...
done. 49160704 trainable parameters.

eval: loss=3.0890 acc=0.0543 b/sec=0.12 time=0.3 min
run:  logs\arithmetic__mixed_longer\tp-transformer\lr=0.0001_bs=64_h=512_f=2048_nl=6_nh=8_d=0.0_Adam\195932581
best: loss=0.1798 acc=0.7459 best since 0 steps and 28122451.3 min

Arguments:
	seed=195932581
	model_name='tp-transformer'
	module_name='arithmetic__mixed_longer'
	load_model='C:\\Users\\anteg\\Desktop\\PROJEKTI\\TP-Transformer-master\\trained\\algebra2d\\lr=0.0001_bs=128_h=512_f=2048_nl=6_nh=8_d=0.0_Adam_\\195932581\\best_eval_model.pt'
	eval_mode=True
	n_steps=10000
	max_strikes=1000
	log_every=50
	eval_every=200
	full_loader=False
	force_remove=False
	force_reload=False
	no_train=False
	log_folder='logs\\arithmetic__mixed_longer\\tp-transformer\\lr=0.0001_bs=64_h=512_f=2048_nl=6_nh=8_d=0.0_Adam\\195932581'
	log_suffix=''
	optimizer='Adam'
	learning_rate=0.0001
	beta1=0.9
	beta2=0.995
	batch_size=64
	max_abs_grad_norm=0.1
	grad_accum_steps=1
	dropout=0.0
	hidden=512
	n_layers=6
	n_heads=8
	filter=2048
	d_r=0
	device=device(type='cuda')
using JIT loader
Loading JIT datasets ...
Creating iterators ...
Loading JIT datasets ...
Creating iterators ...
Building model ...
done. 49165824 trainable parameters.

eval: loss=3.6950 acc=0.0021 b/sec=0.12 time=0.3 min
run:  logs\arithmetic__mixed_longer\tp-transformer\lr=0.0001_bs=64_h=512_f=2048_nl=6_nh=8_d=0.0_Adam\195932581
best: loss=0.6056 acc=0.3541 best since 0 steps and 28122457.3 min

